{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joshua Loyal, January 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = (10, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sliced` package helps you find low dimensional information in your high dimensional data. Furthermore, this information is relevant to the problem's target variable. \n",
    "\n",
    "For example, consider the following data generating process:\n",
    "\n",
    "$$\n",
    "    \\beta = (1, 1, 0, 0, 0, 0, 0, 0, 0, 0)^T\n",
    "$$\n",
    "\n",
    "$$\n",
    "    X \\overset{iid}\\sim N(0, 1), \\quad \\epsilon \\overset{iid}\\sim N(0, 0.5) \n",
    "$$\n",
    "\n",
    "$$\n",
    "    Y = 0.125 \\cdot (X\\beta)^3 + \\epsilon\n",
    "$$\n",
    "\n",
    "Where $X$ is a 10-dimensional feature matrix. Notice that $Y$ only depends on $X$ through a linear combination of the first two features: $X_1 + X_2$. This is a one-dimensional subspace. The methods in `sliced` try to find this subspace.\n",
    "\n",
    "Let's see how `sliced` finds this subspace. We start by generating the dataset described above. It is example dataset included in the `sliced` package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sliced.datasets import make_cubic\n",
    "\n",
    "X, y = make_cubic(random_state=123)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The surface in three-dimensions is displayed below. Note that we normally do not know that $X_1$ and $X_2$ contain all the information about the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_trisurf(X[:, 0], X[:, 1], y, \n",
    "                cmap='viridis', alpha=0.2, edgecolor='none')\n",
    "ax.scatter3D(X[:, 0], X[:, 1], y, c=y, \n",
    "             cmap='viridis', edgecolor='k', s=50, linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn a low dimensional representation we use the `SlicedInverseRegression` algorithm found in `sliced`. Fitting the algorithms is easy since it adheres to the sklearn transformer API. A single hyperparameter `n_directions` indicates the dimension of the subspace. In this case we want a single direction, so we set `n_directions=1`. The `directions_` attribute stores the estimated direction of the subspace once the algorithm is fit. The following fits the SIR algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sliced import SlicedInverseRegression\n",
    "\n",
    "sir = SlicedInverseRegression(n_directions=1)\n",
    "sir.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually perform the dimension reduction we call the `transform` method on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sir = sir.transform(X)\n",
    "\n",
    "plt.scatter(X_sir[:, 0], y,\n",
    "            c=y, cmap='viridis', edgecolors='k', s=80)\n",
    "plt.xlabel('$X\\\\beta_{sir}$')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cubic structure is accuratly identified with a single feature. `sliced` reduced the dimension of the dataset from 10 to 1!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
